import os
from django.core.cache import cache
import pandas as pd
import concurrent.futures
import logging
import psutil
from django.contrib import messages
from ecanguinha.services.combustivel import consultar_combustivel
logger = logging.getLogger(__name__)

def testar_redis_em_debug():
    redis_url = os.getenv("REDIS_URL", "N√ÉO DEFINIDO")
    print(f"DEBUG - REDIS_URL: {redis_url}")
    try:
        cache.set('teste_log', 'valor_log', timeout=60)
        valor = cache.get('teste_log')
        print(f"üß™ Redis funcionando: {valor}")
    except Exception as e:
        print(f"‚ùå Falha ao acessar Redis em modo DEBUG: {e}")


import logging
from ecanguinha.services.combustivel import consultar_combustivel

logger = logging.getLogger(__name__)

# Fun√ß√£o para calcular dinamicamente o n√∫mero de dias v√°lidos
def calcular_dias_validos_dinamicamente(raio, tipo_combustivel, lat, lon, max_dias=10):
    """
    Tenta encontrar o menor n√∫mero de dias que retorna dados v√°lidos da API de combust√≠vel.
    Itera do menor para o maior (2 at√© max_dias).
    Retorna None se n√£o encontrar dados dentro do limite.
    """
    # Itera de 2 at√© o dia m√°ximo para encontrar o menor atraso poss√≠vel
    for dias in range(2, max_dias + 1):
        logger.info(f"Tentando obter dados de combust√≠vel com dias={dias}")
        response = consultar_combustivel(
            tipo_combustivel=tipo_combustivel,
            raio=raio,
            lat=lat,
            lon=lon,
            dias=dias,
        )
        if response and isinstance(response, list) and len(response) > 0:
            logger.info(f"‚úÖ Dados de combust√≠vel encontrados com dias={dias}")
            return dias
        else:
            logger.warning(f"‚ö†Ô∏è Nenhum dado de combust√≠vel encontrado com dias={dias}")

    # Se o loop terminar sem sucesso, sinaliza a falha
    logger.error(f"‚ùå Nenhum dado de combust√≠vel encontrado em at√© {max_dias} dias.")
    return None  # Retorna None para indicar falha total


def obter_produtos(request, gtin_list, raio, my_lat, my_lon, dias):
    """
    Fun√ß√£o para realizar consultas paralelas √† API da SEFAZ com cache, logs e progresso.
    """
    if not request.session.session_key:
        request.session.save()

    resultados = []
    total = len(gtin_list)
    session_key = f"progresso_{request.session.session_key}"

    logger.warning(f"üîë Chave da sess√£o: {request.session.session_key}")
    logger.warning(f"üì¶ Progresso ser√° salvo em: {session_key}")

    if not gtin_list:
        logger.warning("Lista de GTIN est√° vazia.")
        messages.warning(request, "Lista de GTIN est√° vazia.")
        return pd.DataFrame()

    max_workers = min(2, len(gtin_list))
    conclu√≠dos = 0

    logger.info(f"üìä Uso de mem√≥ria antes das requisi√ß√µes: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB")

    # Inicializa progresso no cache
    cache.set(session_key, 0, timeout=300)

    def worker(gtin):
        nonlocal conclu√≠dos
        try:
            resultado = consultar_combustivel(
                tipo_combustivel=1,
                raio=raio,
                lat=my_lat,
                lon=my_lon,
                dias=dias,
                gtin=gtin
            )
            return resultado
        except Exception as e:
            logger.warning(f"Erro ao consultar GTIN {gtin}: {e}")
            return None
        finally:
            conclu√≠dos += 1
            progresso = int((conclu√≠dos / total) * 100)
            cache.set(session_key, progresso, timeout=300)
            logger.warning(f"üìä Progresso atualizado: {progresso}% (GTIN: {gtin})")

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        resultados = list(executor.map(worker, gtin_list))

    logger.warning("‚úÖ Finalizou obten√ß√£o de produtos.")
    return pd.DataFrame([r for r in resultados if r])

def update_progresso_cache(session_key: str, progresso: int):
    """
    Atualiza o progresso no cache com base na chave de sess√£o.
    """
    cache_key = f"progresso_{session_key}"
    cache.set(cache_key, progresso, timeout=300)
    logger.warning(f"üìä Progresso atualizado: {progresso}% (Chave: {cache_key})")
